\chapter{Optimization}
\label{chap:optimization}

Certain LLVM optimizations have been implemented to achieve higher performance for $\rho$-VEX binaries.

\section{Generic binary optimization}
Research has shown \cite{Anthony-Brandon:2013jk} that generic binaries incur a performance penalty because of inefficient register usage. Consider the previous generic binary example again:

\begin{lstlisting}
  add $r0.10  = $r0.10, $r0.11
  add $r0.12  = $r0.12, $r0.13
  add $r0.14  = $r0.14, $r0.8
  add $r0.8   = $r0.8, $r0.9
;;
\end{lstlisting}

This instruction packet is not legal because of the RAW hazard that is caused by r0.8. The current approach to fix the RAW hazard is to split the instruction packet into two separate instructions. 

\begin{lstlisting}
  add $r0.10  = $r0.10, $r0.11
  add $r0.12  = $r0.12, $r0.13
  add $r0.14  = $r0.14, $r0.8
;;
  add $r0.8   = $r0.8, $r0.9
;;
\end{lstlisting}

Because more instruction packets are used the amount of ILP that is extracted decreases and the performance of the resulting binary decreases. Performance could be improved by using a different register for the last assignment of r0.8. 

\subsection{Problem statement}
This kind of optimization poses a significant challenge for VLIW type compilers because the register allocation pass is executed before the VLIW packetization. This implies that the register allocator has no information on which operations will be grouped together and for which operations an extra register should be used.

A solution could be to perform VLIW packetization before register allocation is completed. This would allow the register allocation pass to determine if a RAW hazard occurs inside a packet and to assign an extra register if needed.

In practice this approach is not possible because between the register allocation pass and the VLIW packetizer pass other passes are run that can change the final code. For example the register allocator pass can insert spill code and the prologue / epilogue insertion pass inserts code related to the stack layout. Inserting new instructions into instructions packets that have already been formed is very ugly because "packet spilling" could occur where a packet that is already full needs to move instructions to the next packet, etc. 

A second approach is to form temporary instruction bundles during the scheduling pass and for the scheduler to provide register allocation hints to the register allocator. This is a similar approach to the machine scheduler pass that from the Hexagon target. Unfortunately this proved impractical because liveliness information was not available during the scheduling pass. The Hexagon machine scheduler uses the temporary bundles and certain register allocation metrics to optimize the instruction ordering but the extra information is not passed to the register allocator.

For this paper the choice has been made to make changes to the register allocator itself and to make register allocation less aggressive. The liveliness allocation pass determines when a virtual register is used. The register allocator uses this information to create a register mapping with minimal register pressure.

By increasing the live range of a virtual register it should be possible to force the register allocator to use more registers when multiple virtual registers are used consecutively. Consider again the previous example:

\begin{lstlisting}
  add $r0.10  = $r0.10, $r0.11
  add $r0.12  = $r0.12, $r0.13
  add $r0.14  = $r0.14, $r0.8
  add $r0.8   = $r0.8, $r0.9
;;
\end{lstlisting}

This would be transformed into the following code where the final r0.8 assignment is changed to an unused register. 

\begin{lstlisting}
  add $r0.10  = $r0.10, $r0.11
  add $r0.12  = $r0.12, $r0.13
  add $r0.14  = $r0.14, $r0.8
  add $r0.15  = $r0.8, $r0.9
;;
\end{lstlisting}

\subsection{Implementation} % (fold)
\label{sub:implementation}
The 'LiveIntervals' pass is used to determine the live ranges of each virtual register. The pass uses the 'LiveRangeCalc' class
Each virtual register has an associated 'SlotIndex' which tracks when the register becomes live and when the register is killed. The 'ExtendToUses' method of the 'LiveRangeCalc' class is used to update the SlotIndex to match the latest use of a virtual register. The SlotIndex class also provides method that give information on the MachineBasicBlock (MBB) in which the virtual register is used.

Extending of the liverange has been enabled by getting the boundary of the MBB from the SlotIndex and by extending the SlotIndex to this boundary. This enables the virtual register to be live for the duration of the basic block and will make sure the register allocator will not assign a new virtual register to a previously used physical register.

This approach is not optimal because it will increase the register usage even if RAW hazards do not occur. If more virtual registers are used then physical registers are available the execution speed will drop because extra spill code needs to be inserted.

\section{Scheduling}
The $\rho$-VEX processor has support for using 32 bit immediate values. 8 bit immediate values can be handled in a single $\rho$-VEX instruction. Values larger then 8 bit values borrow space from the adjecant $\rho$-VEX instruction. The following code examples show the maximum amount of instruction in a packet for a 4 issue width $\rho$-VEX processor.

\begin{lstlisting}
  add $r0.10  = $r0.10, 200
  add $r0.11  = $r0.11, 200
  add $r0.12  = $r0.12, 200
  add $r0.13  = $r0.13, 200
;;
\end{lstlisting}

\begin{lstlisting}
  add $r0.10  = $r0.10, 2000
  add $r0.11  = $r0.11, 200
  add $r0.12  = $r0.12, 200
;;
\end{lstlisting}

Large immediate values are used throughout the $\rho$-VEX ISA. Not only arithmatic instruction can use large immediate values but also load and store instructions to represent the address offset.

\begin{lstlisting}
  ldw $r0.2 = 2000[$r0.2]
;;
\end{lstlisting}

\subsection{Problem statement} % (fold)
\label{sub:problem_statement}
Large immediate values can be supported by creating a new instruction itinerary with support for large immediate values. This instruction itinerary would be special because it requires two functional units during VLIW packetization. The algorithm that builds the resource usage DFA needs to be updated to reflect instruction itineraries with multiple functional unit usage.

Unfortunetely this approach is impractical for a couple of reasons. Each instruction that supports immediate values needs to be implemented twice, once for small immediate values and once for large immediate values. This would increase the risk of errors in the Tablegen files because each instruction has multiple definitions that need to be updated when changes are made.

A second approach is to update the VLIW packetizer and to recognize large immediate values during the packetization pass.

% subsection problem_statement (end)

\subsection{implementation} % (fold)
\label{sub:implementation}
During the packetization pass each instruction that uses an immediate value is checked before it is bundled in an instruction bundle. The packetizer determines the size of an immediate value and reserves an extra resource in the DFA when a large immediate value is used.

% subsection implementation (end)



\section{Conclusion}
asd
\acresetall
